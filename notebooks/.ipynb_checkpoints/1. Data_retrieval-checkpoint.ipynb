{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a9270a-e897-4858-9989-77f5201d015f",
   "metadata": {},
   "source": [
    "# 1. Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1376999-807c-41f3-adfe-1619e3c1c356",
   "metadata": {},
   "source": [
    "This notebook handles the retrieval of historical stock price data for the S&P 500 and FTSE 100 tickers using the `yfinance` API. It saves the data locally as CSV files to be used for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8e510-3866-4911-9b7c-22aa5d4b1731",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "We begin by importing the necessary Python libraries for data handling and downloading financial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e31190-d973-4523-91ab-4cfe14446fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcf1c36-6610-46b7-8dd1-f3ebd8cbc821",
   "metadata": {},
   "source": [
    "## Define Ticker Lists\n",
    "We define a sample list of tickers for both S&P 500 and FTSE 100 indices. You can replace these with full index lists if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5540e688-5548-4424-9431-a1a6e2a138f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"JPM\", \"JNJ\", \"CAT\", \"XOM\", \"NEE\"]\n",
    "ftse100_tickers = [\"HSBA.L\", \"LLOY.L\", \"SHEL.L\", \"BP.L\", \"AZN.L\", \"ULVR.L\", \"BAE.L\", \"RIO.L\", \"NG.L\", \"VOD.L\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c79d298-77b2-4cf2-96c2-b4a9bf3b3b52",
   "metadata": {},
   "source": [
    "## Define Download Function\n",
    "This function downloads historical OHLCV (Open, High, Low, Close, Volume) data for each ticker using `yfinance` and saves it as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd5bc8d-eac9-40aa-abc1-3a61c889c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_save_stock_data(tickers, start_date, end_date, save_path=\"data\"):\n",
    "    os.makedirs(save_path, exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            print(f\"Downloading {ticker}...\")\n",
    "            data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "\n",
    "            if data.empty:\n",
    "                print(f\"⚠️ No data found for {ticker}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(save_path, f\"{ticker.replace('.', '_')}.csv\")\n",
    "            data.to_csv(file_path)\n",
    "            print(f\"✅ Saved {ticker} to {file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error downloading {ticker}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed759fea-fd68-4b30-9d9b-821a88952b48",
   "metadata": {},
   "source": [
    "## Download Stock Data\n",
    "We execute the function to retrieve and store historical stock data for each ticker in the respective folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01fefa43-c0f6-4889-99d3-5279f0dd27dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading AAPL...\n",
      "YF.download() has changed argument auto_adjust default to True\n",
      "✅ Saved AAPL to ../data/unprocessed/sp500\\AAPL.csv\n",
      "Downloading MSFT...\n",
      "✅ Saved MSFT to ../data/unprocessed/sp500\\MSFT.csv\n",
      "Downloading GOOGL...\n",
      "✅ Saved GOOGL to ../data/unprocessed/sp500\\GOOGL.csv\n",
      "Downloading AMZN...\n",
      "✅ Saved AMZN to ../data/unprocessed/sp500\\AMZN.csv\n",
      "Downloading TSLA...\n",
      "✅ Saved TSLA to ../data/unprocessed/sp500\\TSLA.csv\n",
      "Downloading JPM...\n",
      "✅ Saved JPM to ../data/unprocessed/sp500\\JPM.csv\n",
      "Downloading JNJ...\n",
      "✅ Saved JNJ to ../data/unprocessed/sp500\\JNJ.csv\n",
      "Downloading CAT...\n",
      "✅ Saved CAT to ../data/unprocessed/sp500\\CAT.csv\n",
      "Downloading XOM...\n",
      "✅ Saved XOM to ../data/unprocessed/sp500\\XOM.csv\n",
      "Downloading NEE...\n",
      "✅ Saved NEE to ../data/unprocessed/sp500\\NEE.csv\n",
      "Downloading HSBA.L...\n",
      "✅ Saved HSBA.L to ../data/unprocessed/ftse100\\HSBA_L.csv\n",
      "Downloading LLOY.L...\n",
      "✅ Saved LLOY.L to ../data/unprocessed/ftse100\\LLOY_L.csv\n",
      "Downloading SHEL.L...\n",
      "✅ Saved SHEL.L to ../data/unprocessed/ftse100\\SHEL_L.csv\n",
      "Downloading BP.L...\n",
      "✅ Saved BP.L to ../data/unprocessed/ftse100\\BP_L.csv\n",
      "Downloading AZN.L...\n",
      "✅ Saved AZN.L to ../data/unprocessed/ftse100\\AZN_L.csv\n",
      "Downloading ULVR.L...\n",
      "✅ Saved ULVR.L to ../data/unprocessed/ftse100\\ULVR_L.csv\n",
      "Downloading BAE.L...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['BAE.L']: YFPricesMissingError('possibly delisted; no price data found  (1d 2020-01-01 -> 2025-01-01)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No data found for BAE.L. Skipping.\n",
      "Downloading RIO.L...\n",
      "✅ Saved RIO.L to ../data/unprocessed/ftse100\\RIO_L.csv\n",
      "Downloading NG.L...\n",
      "✅ Saved NG.L to ../data/unprocessed/ftse100\\NG_L.csv\n",
      "Downloading VOD.L...\n",
      "✅ Saved VOD.L to ../data/unprocessed/ftse100\\VOD_L.csv\n"
     ]
    }
   ],
   "source": [
    "download_and_save_stock_data(sp500_tickers, \"2020-01-01\", \"2025-01-01\", save_path=\"../data/unprocessed/sp500\")\n",
    "download_and_save_stock_data(ftse100_tickers, \"2020-01-01\", \"2025-01-01\", save_path=\"../data/unprocessed/ftse100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e942f339-2c91-440f-a5bb-a97a780b4d89",
   "metadata": {},
   "source": [
    "## Verify Downloaded Files\n",
    "We list the files to confirm successful data retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45953a8f-c560-4f0c-b842-ba5245a4f3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL.csv',\n",
       " 'AMZN.csv',\n",
       " 'CAT.csv',\n",
       " 'GOOGL.csv',\n",
       " 'JNJ.csv',\n",
       " 'JPM.csv',\n",
       " 'MSFT.csv',\n",
       " 'NEE.csv',\n",
       " 'TSLA.csv',\n",
       " 'XOM.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../data/unprocessed/sp500/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a63a33a-a894-4bf5-adaa-c5989055fed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AZN_L.csv',\n",
       " 'BP_L.csv',\n",
       " 'HSBA_L.csv',\n",
       " 'LLOY_L.csv',\n",
       " 'NG_L.csv',\n",
       " 'RIO_L.csv',\n",
       " 'SHEL_L.csv',\n",
       " 'ULVR_L.csv',\n",
       " 'VOD_L.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../data/unprocessed/ftse100/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a81dad-4a8a-4d2e-be90-519967e64586",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_files = os.listdir(\"../data/unprocessed/sp500/\")\n",
    "ftse100_files = os.listdir(\"../data/unprocessed/ftse100/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8544fc98-7248-43c5-9092-b3815a077b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_csvs = [f for f in sp500_files if f.endswith(\".csv\")]\n",
    "ftse100_csvs = [f for f in ftse100_files if f.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0a477af-d8da-4652-9cce-4006b6cbe5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL.csv',\n",
       " 'AMZN.csv',\n",
       " 'CAT.csv',\n",
       " 'GOOGL.csv',\n",
       " 'JNJ.csv',\n",
       " 'JPM.csv',\n",
       " 'MSFT.csv',\n",
       " 'NEE.csv',\n",
       " 'TSLA.csv',\n",
       " 'XOM.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0ba6e9f-c2d0-42ed-b1c4-84591bdcc91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAPL.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_csvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "898b01ff-6a60-4a10-87da-e6c9c2d6cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_path = \"../data/unprocessed/sp500/\"\n",
    "ftse100_path = \"../data/unprocessed/ftse100/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3df1f977-d96f-474a-955d-44c0e780c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nulls(csv_list, path):\n",
    "    tickers_with_nulls = []\n",
    "\n",
    "    for ticker in csv_list:\n",
    "        filepath = os.path.join(path, ticker)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            null_counts = df.isnull().sum()\n",
    "            nulls_present = null_counts[null_counts > 0]\n",
    "\n",
    "            if not nulls_present.empty:\n",
    "                print(f\"⚠️ Null values detected in {ticker}:\")\n",
    "                print(nulls_present)\n",
    "                tickers_with_nulls.append(ticker)\n",
    "            else:\n",
    "                print(f\"✅ No null values in {ticker}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error reading {ticker}: {e}\")\n",
    "\n",
    "    print(\"\\n🔍 Summary:\")\n",
    "    print(f\"{len(tickers_with_nulls)} files had nulls out of {len(csv_list)} total.\")\n",
    "\n",
    "    return tickers_with_nulls  # useful if you want to inspect/fix later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caece644-66dd-47f2-8d96-71eb38c049d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Null values detected in AAPL.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in AMZN.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in CAT.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in GOOGL.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in JNJ.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in JPM.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in MSFT.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in NEE.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in TSLA.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in XOM.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "\n",
      "🔍 Summary:\n",
      "10 files had nulls out of 10 total.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AAPL.csv',\n",
       " 'AMZN.csv',\n",
       " 'CAT.csv',\n",
       " 'GOOGL.csv',\n",
       " 'JNJ.csv',\n",
       " 'JPM.csv',\n",
       " 'MSFT.csv',\n",
       " 'NEE.csv',\n",
       " 'TSLA.csv',\n",
       " 'XOM.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_nulls(sp500_csvs, sp500_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbd02f83-7fe6-43be-b185-878e3d8b7066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Null values detected in AZN_L.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in BP_L.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in HSBA_L.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in LLOY_L.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in NG_L.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in RIO_L.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in SHEL_L.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in ULVR_L.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "⚠️ Null values detected in VOD_L.csv:\n",
      "Close     1\n",
      "High      1\n",
      "Low       1\n",
      "Open      1\n",
      "Volume    1\n",
      "dtype: int64\n",
      "\n",
      "🔍 Summary:\n",
      "9 files had nulls out of 9 total.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AZN_L.csv',\n",
       " 'BP_L.csv',\n",
       " 'HSBA_L.csv',\n",
       " 'LLOY_L.csv',\n",
       " 'NG_L.csv',\n",
       " 'RIO_L.csv',\n",
       " 'SHEL_L.csv',\n",
       " 'ULVR_L.csv',\n",
       " 'VOD_L.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_nulls(ftse100_csvs, ftse100_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38bce0eb-8f57-44fa-9e8b-a0552b484833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_save_csvs(csv_list, input_path, output_path):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    cleaned_count = 0\n",
    "\n",
    "    for ticker in csv_list:\n",
    "        input_file = os.path.join(input_path, ticker)\n",
    "        output_file = os.path.join(output_path, ticker)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(input_file)\n",
    "            initial_len = len(df)\n",
    "\n",
    "            # Drop rows with any nulls\n",
    "            df_cleaned = df.dropna()\n",
    "            cleaned_len = len(df_cleaned)\n",
    "\n",
    "            # Save cleaned file\n",
    "            df_cleaned.to_csv(output_file, index=False)\n",
    "            print(f\"✅ Cleaned {ticker}: removed {initial_len - cleaned_len} rows\")\n",
    "\n",
    "            cleaned_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {ticker}: {e}\")\n",
    "\n",
    "    print(f\"\\n🧹 Finished cleaning. {cleaned_count} files processed and saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc308042-8666-43d9-8a14-0a87989db11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned AAPL.csv: removed 1 rows\n",
      "✅ Cleaned AMZN.csv: removed 1 rows\n",
      "✅ Cleaned CAT.csv: removed 1 rows\n",
      "✅ Cleaned GOOGL.csv: removed 1 rows\n",
      "✅ Cleaned JNJ.csv: removed 1 rows\n",
      "✅ Cleaned JPM.csv: removed 1 rows\n",
      "✅ Cleaned MSFT.csv: removed 1 rows\n",
      "✅ Cleaned NEE.csv: removed 1 rows\n",
      "✅ Cleaned TSLA.csv: removed 1 rows\n",
      "✅ Cleaned XOM.csv: removed 1 rows\n",
      "\n",
      "🧹 Finished cleaning. 10 files processed and saved to: ../data/processed/sp500\n"
     ]
    }
   ],
   "source": [
    "clean_and_save_csvs(\n",
    "    csv_list=sp500_csvs,\n",
    "    input_path=\"../data/unprocessed/sp500\",\n",
    "    output_path=\"../data/processed/sp500\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e5a2b34-bc41-4d4d-a32f-8d7906226455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned AZN_L.csv: removed 1 rows\n",
      "✅ Cleaned BP_L.csv: removed 1 rows\n",
      "✅ Cleaned HSBA_L.csv: removed 1 rows\n",
      "✅ Cleaned LLOY_L.csv: removed 1 rows\n",
      "✅ Cleaned NG_L.csv: removed 1 rows\n",
      "✅ Cleaned RIO_L.csv: removed 1 rows\n",
      "✅ Cleaned SHEL_L.csv: removed 1 rows\n",
      "✅ Cleaned ULVR_L.csv: removed 1 rows\n",
      "✅ Cleaned VOD_L.csv: removed 1 rows\n",
      "\n",
      "🧹 Finished cleaning. 9 files processed and saved to: ../data/processed/ftse100\n"
     ]
    }
   ],
   "source": [
    "clean_and_save_csvs(\n",
    "    csv_list=ftse100_csvs,\n",
    "    input_path=\"../data/unprocessed/ftse100\",\n",
    "    output_path=\"../data/processed/ftse100\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cad0661-a8bf-4d2e-8cee-d6f196e3e7ed",
   "metadata": {},
   "source": [
    "### We save the cleaned files for further analysis in 2.Feature_engineering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6afb24d-5075-4fd9-bfda-976f80bb5a02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (clustering-env)",
   "language": "python",
   "name": "clustering-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
